# -*- coding: utf-8 -*-
"""
M√≥dulo: Extractor de Licitaciones (LicitacionScraper)
---------------------------------------------------
Este m√≥dulo implementa el pipeline de descubrimiento y captura de datos 
desde el portal Mercado P√∫blico. 

Responsabilidades:
1. Consultar la API oficial para el descubrimiento de nuevas oportunidades.
2. Filtrar resultados basados en el perfil de b√∫squeda del usuario.
3. Ejecutar la navegaci√≥n automatizada (Selenium) para la extracci√≥n de 
   detalles t√©cnicos y cl√°usulas desde la ficha profunda.
"""

import requests
import os
import time
import re
from datetime import datetime
from dotenv import load_dotenv
from core.database_mgr import DatabaseManager
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# Cargar configuraci√≥n de entorno para acceso a API y tickets
load_dotenv()

class LicitacionScraper:
    """
    Clase encargada del descubrimiento y extracci√≥n de datos.
    
    Centraliza la comunicaci√≥n con la API de Mercado P√∫blico y gestiona el 
    ciclo de vida del navegador automatizado para el scraping de fichas t√©cnicas.
    """

    def __init__(self, db_manager):
        """
        Inicializar el scraper e inyectar la dependencia de persistencia.

        Args:
            db_manager (DatabaseManager): Instancia para verificar existencia 
                                          y perfiles de b√∫squeda.
        """
        self.db = db_manager
        self.api_ticket = os.getenv("MP_TICKET")
        self.base_url = "https://api.mercadopublico.cl/servicios/v1/publico/licitaciones.json"

    # -------------------------------------------------------------------
    # PARTE 1: DESCUBRIMIENTO GENERAL (API REST)
    # -------------------------------------------------------------------

    def obtener_keywords_busqueda(self):
        """
        Consultar las palabras clave configuradas en el perfil del usuario.

        Returns:
            list: Lista de t√©rminos de b√∫squeda normalizados.
        """
        perfil = self.db.obtener_perfil()
        if not perfil or not perfil['keywords_pos']:
            print("‚ö†Ô∏è No hay palabras clave configuradas en el perfil.")
            return []
        
        # Limpiar espacios y segmentar la cadena de texto en una lista ejecutable
        return [k.strip() for k in perfil['keywords_pos'].split(',')]
    
    def descubrir_licitaciones_del_dia(self):
        """
        Consultar la API masiva para obtener todas las licitaciones de la fecha actual.

        Returns:
            list: Listado bruto de licitaciones encontradas.
        """
        if not self.api_ticket:
            print("‚ùå Error: MP_TICKET no encontrado en .env")
            return []
        
        # Formatear la fecha seg√∫n el est√°ndar requerido por la API (DDMMAAAA)
        fecha_hoy = datetime.now().strftime("%d%m%Y")
        parametros = {
            'fecha': fecha_hoy,
            'ticket': self.api_ticket
        }

        try:
            print(f"üîç Buscando licitaciones publicadas hoy: {fecha_hoy}...")
            respuesta = requests.get(self.base_url, params=parametros)

            if respuesta.status_code == 200:
                datos = respuesta.json()
                return datos.get('Listado', [])
            else:
                print(f"‚ùå Error en la API: {respuesta.status_code} - {respuesta.reason}")
                return []
        except Exception as e:
            print(f"‚ùå Error de conexi√≥n al intentar descubrir: {e}")
            return []
        
    def filtrar_licitaciones_relevantes(self, lista_bruta):
        """
        Aplicar criterios de filtrado t√©cnico y estrat√©gico sobre el listado bruto.
        
        Criterios:
        - Estado 5: √önicamente licitaciones en estado 'Publicada'.
        - Keywords: Coincidencia en el t√≠tulo con el rubro del usuario.
        - Unicidad: Exclusi√≥n de registros ya existentes en la base de datos.

        Args:
            lista_bruta (list): Listado original de la API.

        Returns:
            list: Licitaciones aptas para procesamiento profundo.
        """
        keywords = self.obtener_keywords_busqueda()
        licitaciones_interesantes = []
        
        # Estado 5 representa 'Publicada', fase activa para participar
        ESTADOS_VIGENTES = [5] 

        print(f"üßê Filtrando {len(lista_bruta)} licitaciones por estado y relevancia...")

        for licit in lista_bruta:
            nombre_licit = (licit.get('Nombre') or "").lower()
            codigo = licit.get('CodigoExterno')
            estado = licit.get('CodigoEstado')

            # Validaci√≥n de triple factor para optimizar recursos de scraping
            if estado in ESTADOS_VIGENTES:
                if any(key.lower() in nombre_licit for key in keywords):
                    if not self.db.existe_licitacion(codigo):
                        licitaciones_interesantes.append(licit)
            
        print(f"üéØ Filtro completado: {len(licitaciones_interesantes)} licitaciones aptas.")
        return licitaciones_interesantes
    
    def ejecutar_pipeline_descubrimiento(self):
        """
        Orquestar el flujo de descubrimiento y pre-filtrado.

        Returns:
            list: Candidatos finales para el an√°lisis profundo.
        """
        listado_total = self.descubrir_licitaciones_del_dia()

        if not listado_total:
            print("üëÄ No se encontraron licitaciones nuevas en el listado general.")
            return []
        
        print(f"üìã Total de licitaciones publicadas hoy: {len(listado_total)}")
        finales = self.filtrar_licitaciones_relevantes(listado_total)
        return finales
    
    # -------------------------------------------------------------------
    # PARTE 2: EXTRACCI√ìN PROFUNDA (SELENIUM)
    # -------------------------------------------------------------------

    def extraer_detalle_licitacion(self, codigo_licitacion):
        """
        Navegar al portal Mercado P√∫blico para capturar el contenido t√©cnico detallado.
        
        Utiliza t√©cnicas de automatizaci√≥n para superar iframes complejos y 
        pop-ups del portal oficial.

        Args:
            codigo_licitacion (str): C√≥digo externo (ej: 1234-56-LP24).

        Returns:
            dict: Diccionario con link, descripci√≥n t√©cnica y metadatos capturados.
        """
        url_home = "https://www.mercadopublico.cl"
        chrome_options = Options()
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("window-size=1920,1080")
        # Simulaci√≥n de User-Agent para minimizar bloqueos por fingerprinting
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
        
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
        wait = WebDriverWait(driver, 25) 
        
        resultado = {
            "link": "No disponible",
            "descripcion_pro": "No se pudo extraer el detalle t√©cnico.",
            "organismo": "No detectado",
            "titulo_oficial": "Sin t√≠tulo",
            "fecha_publicacion": datetime.now().strftime("%Y-%m-%d"),
            "reclamo_pago": "No informado"
        }

        try:
            driver.get(url_home)

            # Gesti√≥n proactiva de alertas/pop-ups del portal
            try:
                WebDriverWait(driver, 3).until(EC.alert_is_present())
                alert = driver.switch_to.alert
                print(f"‚ö†Ô∏è Alerta de portal detectada ('{alert.text}'), cerrando...")
                alert.accept()
                time.sleep(1)
                driver.refresh()
            except:
                pass
            
            # Ejecutar b√∫squeda por c√≥digo externo
            search_input = wait.until(EC.visibility_of_element_located((By.ID, "txtBuscar")))
            search_input.clear()
            search_input.send_keys(codigo_licitacion)
            
            # Clic mediante JavaScript para asegurar interacci√≥n en elementos superpuestos
            try:
                boton_buscar = wait.until(EC.element_to_be_clickable((By.ID, "btnBuscar")))
                driver.execute_script("arguments[0].click();", boton_buscar)
            except:
                driver.execute_script("document.getElementById('btnBuscar').click();")

            # Salto al iframe de resultados para acceder al DOM din√°mico
            wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, "form-iframe")))

            # Localizar el enlace de la licitaci√≥n espec√≠fica mediante el atributo onclick
            selector_xpath = f"//a[contains(@onclick, '{codigo_licitacion}')]"
            enlace_elem = wait.until(EC.presence_of_element_located((By.XPATH, selector_xpath)))
            onclick_txt = enlace_elem.get_attribute("onclick")
            url_match = re.search(r"'(http.*?)'", onclick_txt)
            
            if url_match:
                resultado["link"] = url_match.group(1)
                
                # Navegar a la ficha t√©cnica final
                driver.get(resultado["link"])
                
                # Sincronizaci√≥n: Esperar carga real del contenido textual
                wait.until(lambda d: d.find_element(By.TAG_NAME, "body").text.strip() != "")
                time.sleep(4) 
                
                # Extracci√≥n robusta: Captura del texto en el nivel principal y sub-iframes
                driver.switch_to.default_content()
                texto_final = driver.execute_script("return document.body.innerText;")
                
                # Si la captura es insuficiente, iterar sobre iframes internos (anidamiento profundo)
                if len(texto_final.strip()) < 1000:
                    iframes = driver.find_elements(By.TAG_NAME, "iframe")
                    for i in range(len(iframes)):
                        try:
                            driver.switch_to.default_content()
                            driver.switch_to.frame(i)
                            texto_final += "\n" + driver.execute_script("return document.body.innerText;")
                        except:
                            continue
                
                resultado["descripcion_pro"] = texto_final
                
                # An√°lisis preventivo: Rescatar metadatos si est√°n presentes en texto plano
                if "Organismo" in texto_final:
                    match_org = re.search(r"Nombre del Organismo\s*:\s*(.*)", texto_final)
                    if match_org: resultado["organismo"] = match_org.group(1).strip()

            return resultado
        
        except Exception as e:
            print(f"‚ö†Ô∏è Error en extracci√≥n de {codigo_licitacion}: {str(e)}")
            return resultado
        finally:
            driver.quit()